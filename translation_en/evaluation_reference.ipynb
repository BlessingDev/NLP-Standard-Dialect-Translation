{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02863eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.translate import bleu_score\n",
    "\n",
    "os.chdir(r\"D:\\박준호\\2024년\\NLP-Standard-Dialect-Transformation\")\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c54105ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "397b4aecf6b44634bbe157bb27b582f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from metric import compute_chrf_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5dab00",
   "metadata": {},
   "source": [
    "강원도 방언 test set 개수 맞추기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f53ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = \"gangwon\"\n",
    "m = \"opus-mt\"\n",
    "path_to_trans_result = \"./translation_english/prediction/\"\n",
    "path_to_reference = \"./translation_english/reference/\"\n",
    "\n",
    "trans_file_path = os.path.join(path_to_trans_result, \"{0}/{1}.json\".format(r, m))\n",
    "with open(trans_file_path, mode=\"rt\", encoding=\"utf-8\") as f:\n",
    "    json_list = json.loads(f.read())\n",
    "result_df = pd.DataFrame(json_list)\n",
    "\n",
    "ref_file_path = os.path.join(path_to_reference, \"{0}/reference.json\".format(r))\n",
    "with open(ref_file_path, mode=\"rt\", encoding=\"utf-8\") as f:\n",
    "    json_list = json.loads(f.read())\n",
    "ref_df = pd.DataFrame(json_list)\n",
    "\n",
    "# 왜 두 개 길이가 다른가?\n",
    "opus_source_list = result_df[\"prediction_source\"].to_list()\n",
    "opus_source_dict = dict(zip(opus_source_list, range(len(opus_source_list))))\n",
    "\n",
    "excluded_list = []\n",
    "for i in range(len(ref_df)):\n",
    "    row = ref_df.iloc[i]\n",
    "    if row[\"standard_source\"] not in opus_source_dict:\n",
    "        excluded_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb51257f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>standard_source</th>\n",
       "      <th>standard_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91328</th>\n",
       "      <td>어~ 음식 중에 이제 음식 중에 하나인 것 같아 그리고</td>\n",
       "      <td>I think it's one of the foods now.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91329</th>\n",
       "      <td>음~ 어~ 이제 뼛국 같은 경우도 지금은 해 주 어~ 없어서 못 먹지.</td>\n",
       "      <td>I think it would be better to translate the sentence as a whole rather than breaking it down. Here is the translation:\\n\\n\"Ah, um, I guess I won't be able to eat it now, huh?\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91330</th>\n",
       "      <td>어~ 없어서 못 먹지 그게 굉장한 오랜 시간의 정성이 필요한 음식이잖아.</td>\n",
       "      <td>That's a tough one to give up, you know it takes a lot of effort and time to make that food.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91331</th>\n",
       "      <td>엄청 큰 솥단지에다가 이제 뼈랑 이게 국</td>\n",
       "      <td>A gigantic pot with bones and this is a soup.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91332</th>\n",
       "      <td>그걸 으 야채라든가 이런 걸 넣고 푹 이제</td>\n",
       "      <td>That stuff in it or add some vegetables and now it's okay.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91333</th>\n",
       "      <td>끓이면서 위에 있는 불순물 떠 내고</td>\n",
       "      <td>Boiling and then removing the impurities that float on top.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91334</th>\n",
       "      <td>굉장히 약불로 하다가 굉장한 오랜 시간 동안</td>\n",
       "      <td>Very faintly for a very long time.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91335</th>\n",
       "      <td>그래서 보면은 항상 어머니가 음~ 그걸 만들 때는 큰 솥단지에다가 항상 끓이셨는데</td>\n",
       "      <td>So then I see, it's always my mom who does it. When she makes that, she always boils it in a big pot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91336</th>\n",
       "      <td>그러면은 그걸 가지고 진짜 한 한 달은 먹었었던 것 같아 진짜</td>\n",
       "      <td>I think I really ate that for a whole month.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91337</th>\n",
       "      <td>내가 그래서 싫어했었던 것도 같아 왜냐면 한 번에 할 때 많은 양을 하다 보니까</td>\n",
       "      <td>I used to dislike that too because when I do it all at once, I end up doing a lot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91338</th>\n",
       "      <td>어렸을 때야 워낙 초딩 입맛이었고 하다 보니</td>\n",
       "      <td>When I was young, I had a childish taste, and it's been like that ever since.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91339</th>\n",
       "      <td>소고기는 진짜 정확하게 언제 먹었는지 기억은 안 나는 것 같은데 아마</td>\n",
       "      <td>I think I had beef sometime, but I'm not really sure when.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91340</th>\n",
       "      <td>인제 고기 부패를 많이 갔는데 거기에도 아마 소고기가 있기는 했어.</td>\n",
       "      <td>I went to Inje and the meat was spoiled a lot, but I think there might have been beef there as well.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91341</th>\n",
       "      <td>근데 질이 굉장히 낮은 고기여 갖고</td>\n",
       "      <td>But the quality is extremely low.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91342</th>\n",
       "      <td>어렸을 때 삼겹살이라던가 거기 항상 냉동이긴 했는데 어~ 그거를 많이 먹었었던 것 같아.</td>\n",
       "      <td>When I was young, I used to eat a lot of pork belly and it was always frozen there.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91343</th>\n",
       "      <td>먹었었던 것 같아 사실 어~ 젊었을 때나 어렸을 때라던가 이럴 때는 워낙 소고기가 비싸다 보니까</td>\n",
       "      <td>I was probably able to eat it, but actually, back when I was young or when I was even younger, it was so expensive because of the high price of beef.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91344</th>\n",
       "      <td>내가 일을 하면서 뭔가 쉽사리 접근할 수 있었던 이제 부분은 아니었어서</td>\n",
       "      <td>I couldn't access something easily while working anymore.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             standard_source  \\\n",
       "91328                         어~ 음식 중에 이제 음식 중에 하나인 것 같아 그리고   \n",
       "91329                음~ 어~ 이제 뼛국 같은 경우도 지금은 해 주 어~ 없어서 못 먹지.   \n",
       "91330               어~ 없어서 못 먹지 그게 굉장한 오랜 시간의 정성이 필요한 음식이잖아.   \n",
       "91331                                 엄청 큰 솥단지에다가 이제 뼈랑 이게 국   \n",
       "91332                                그걸 으 야채라든가 이런 걸 넣고 푹 이제   \n",
       "91333                                    끓이면서 위에 있는 불순물 떠 내고   \n",
       "91334                               굉장히 약불로 하다가 굉장한 오랜 시간 동안   \n",
       "91335          그래서 보면은 항상 어머니가 음~ 그걸 만들 때는 큰 솥단지에다가 항상 끓이셨는데   \n",
       "91336                     그러면은 그걸 가지고 진짜 한 한 달은 먹었었던 것 같아 진짜   \n",
       "91337           내가 그래서 싫어했었던 것도 같아 왜냐면 한 번에 할 때 많은 양을 하다 보니까   \n",
       "91338                               어렸을 때야 워낙 초딩 입맛이었고 하다 보니   \n",
       "91339                 소고기는 진짜 정확하게 언제 먹었는지 기억은 안 나는 것 같은데 아마   \n",
       "91340                  인제 고기 부패를 많이 갔는데 거기에도 아마 소고기가 있기는 했어.   \n",
       "91341                                    근데 질이 굉장히 낮은 고기여 갖고   \n",
       "91342      어렸을 때 삼겹살이라던가 거기 항상 냉동이긴 했는데 어~ 그거를 많이 먹었었던 것 같아.   \n",
       "91343  먹었었던 것 같아 사실 어~ 젊었을 때나 어렸을 때라던가 이럴 때는 워낙 소고기가 비싸다 보니까   \n",
       "91344                내가 일을 하면서 뭔가 쉽사리 접근할 수 있었던 이제 부분은 아니었어서   \n",
       "\n",
       "                                                                                                                                                                       standard_target  \n",
       "91328                                                                                                                                               I think it's one of the foods now.  \n",
       "91329  I think it would be better to translate the sentence as a whole rather than breaking it down. Here is the translation:\\n\\n\"Ah, um, I guess I won't be able to eat it now, huh?\"  \n",
       "91330                                                                                     That's a tough one to give up, you know it takes a lot of effort and time to make that food.  \n",
       "91331                                                                                                                                    A gigantic pot with bones and this is a soup.  \n",
       "91332                                                                                                                       That stuff in it or add some vegetables and now it's okay.  \n",
       "91333                                                                                                                      Boiling and then removing the impurities that float on top.  \n",
       "91334                                                                                                                                               Very faintly for a very long time.  \n",
       "91335                                                                            So then I see, it's always my mom who does it. When she makes that, she always boils it in a big pot.  \n",
       "91336                                                                                                                                     I think I really ate that for a whole month.  \n",
       "91337                                                                                               I used to dislike that too because when I do it all at once, I end up doing a lot.  \n",
       "91338                                                                                                    When I was young, I had a childish taste, and it's been like that ever since.  \n",
       "91339                                                                                                                       I think I had beef sometime, but I'm not really sure when.  \n",
       "91340                                                                             I went to Inje and the meat was spoiled a lot, but I think there might have been beef there as well.  \n",
       "91341                                                                                                                                                But the quality is extremely low.  \n",
       "91342                                                                                              When I was young, I used to eat a lot of pork belly and it was always frozen there.  \n",
       "91343                            I was probably able to eat it, but actually, back when I was young or when I was even younger, it was so expensive because of the high price of beef.  \n",
       "91344                                                                                                                        I couldn't access something easily while working anymore.  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_df.iloc[excluded_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafe3473",
   "metadata": {},
   "source": [
    "이거 그냥 길이로 잘라 버렸네..\n",
    "\n",
    "대체 왜 그런 짓을?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce54a7b",
   "metadata": {},
   "source": [
    "## 미중일 dirct 성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cd82744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chrf_of_direct_translation(path_to_trans_result, path_to_reference, regions, models, word_order=2):\n",
    "    \n",
    "    eval_dict = dict()\n",
    "    for r in regions:\n",
    "        print(r)\n",
    "        result_dict = dict()\n",
    "        df_len = 0\n",
    "        for m in models:\n",
    "            json_list = []\n",
    "            trans_file_path = os.path.join(path_to_trans_result, \"{0}/{1}.json\".format(r, m))\n",
    "            with open(trans_file_path, mode=\"rt\", encoding=\"utf-8\") as f:\n",
    "                json_list = json.loads(f.read())\n",
    "            \n",
    "            df = pd.DataFrame(json_list)\n",
    "            result_dict[m] = df\n",
    "            if df_len > 0:\n",
    "                df_len = min(df_len, len(df))\n",
    "            else:\n",
    "                df_len = len(df)\n",
    "        \n",
    "        # Load reference data\n",
    "        ref_file_path = os.path.join(path_to_reference, \"{0}/reference.json\".format(r))\n",
    "        with open(ref_file_path, mode=\"rt\", encoding=\"utf-8\") as f:\n",
    "            json_list = json.loads(f.read())\n",
    "        \n",
    "        ref_df = pd.DataFrame(json_list)\n",
    "        \n",
    "        r_eval_dict = dict()\n",
    "        \n",
    "        # Ensure the reference DataFrame has the same length as the result DataFrames\n",
    "        \n",
    "        \n",
    "        for m in models:\n",
    "            len_result = len(result_dict[m])\n",
    "            r_eval_dict[m] = compute_chrf_score(\n",
    "                y_true=ref_df.iloc[range(len_result)][\"standard_target\"].to_list(), \n",
    "                y_pred=result_dict[m][\"dialect_target\"].to_list(),\n",
    "                word_order=word_order\n",
    "            )\n",
    "\n",
    "        eval_dict[r] = r_eval_dict\n",
    "    \n",
    "    return eval_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6978b6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chungcheong\n",
      "gangwon\n",
      "gyeongsang\n",
      "jeju\n",
      "jeonla\n"
     ]
    }
   ],
   "source": [
    "regions = [\"chungcheong\", \"gangwon\", \"gyeongsang\", \"jeju\", \"jeonla\"]\n",
    "models = [\"opus-mt\", \"m2m_100_1.2B\", \"exaone\"]\n",
    "\n",
    "eval_dict_chrf = chrf_of_direct_translation(\"./translation_en/baseline/\", \"./translation_en/reference/\", regions, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4847ad15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chungcheong': {'opus-mt': 29.899736299710117, 'm2m_100_1.2B': 29.927620701656622, 'exaone': 41.84524814235252}, 'gangwon': {'opus-mt': 28.11569028009181, 'm2m_100_1.2B': 27.828509422928153, 'exaone': 39.58344502296015}, 'gyeongsang': {'opus-mt': 29.890192821744694, 'm2m_100_1.2B': 29.688938767097884, 'exaone': 42.18258264894414}, 'jeju': {'opus-mt': 25.458562069697656, 'm2m_100_1.2B': 25.157719904722757, 'exaone': 36.639162061946465}, 'jeonla': {'opus-mt': 28.790851705080385, 'm2m_100_1.2B': 28.846113804400535, 'exaone': 40.73570025731394}}\n"
     ]
    }
   ],
   "source": [
    "print(eval_dict_chrf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7b7e0506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chungcheong\n",
      "gangwon\n",
      "gyeongsang\n",
      "jeju\n",
      "jeonla\n"
     ]
    }
   ],
   "source": [
    "regions = [\"chungcheong\", \"gangwon\", \"gyeongsang\", \"jeju\", \"jeonla\"]\n",
    "models = [\"m2m_100_1.2B\", \"exaone\"]\n",
    "\n",
    "eval_dict_chrf = chrf_of_direct_translation(\"./translation_zh/baseline/\", \"./translation_zh/reference/\", regions, models, word_order=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ed01dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chungcheong': {'m2m_100_1.2B': 10.233893096873826, 'exaone': 13.870981488308445}, 'gangwon': {'m2m_100_1.2B': 9.506399012629473, 'exaone': 13.196685395020877}, 'gyeongsang': {'m2m_100_1.2B': 10.572085041798958, 'exaone': 14.480980567018761}, 'jeju': {'m2m_100_1.2B': 8.736314809763911, 'exaone': 12.103708324401264}, 'jeonla': {'m2m_100_1.2B': 9.958133562191037, 'exaone': 13.488134644613927}}\n"
     ]
    }
   ],
   "source": [
    "print(eval_dict_chrf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83e81187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chungcheong\n",
      "gangwon\n",
      "gyeongsang\n",
      "jeju\n",
      "jeonla\n"
     ]
    }
   ],
   "source": [
    "regions = [\"chungcheong\", \"gangwon\", \"gyeongsang\", \"jeju\", \"jeonla\"]\n",
    "models = [\"m2m_100_1.2B\", \"exaone\"]\n",
    "\n",
    "eval_dict_chrf = chrf_of_direct_translation(\"./translation_jp/baseline/\", \"./translation_jp/reference/\", regions, models, word_order=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7615a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chungcheong': {'m2m_100_1.2B': 14.257823234391228, 'exaone': 20.964232363478796}, 'gangwon': {'m2m_100_1.2B': 12.520343934959389, 'exaone': 19.435285698119962}, 'gyeongsang': {'m2m_100_1.2B': 14.329880040577816, 'exaone': 21.508564801948456}, 'jeju': {'m2m_100_1.2B': 10.760888324268258, 'exaone': 17.06342426369407}, 'jeonla': {'m2m_100_1.2B': 13.8149272022079, 'exaone': 20.435548142894913}}\n"
     ]
    }
   ],
   "source": [
    "print(eval_dict_chrf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ff2296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = \"chungcheong\"\n",
    "model = \"exaone\"\n",
    "path_to_translation = \"./translation_english/\"\n",
    "\n",
    "file_path = os.path.join(path_to_translation, \"reference/{0}/reference.json\".format(region))\n",
    "    \n",
    "json_list = []\n",
    "\n",
    "with open(file_path, mode=\"rt\", encoding=\"utf-8\") as f:\n",
    "    json_list = json.loads(f.read())\n",
    "\n",
    "reference_df = pd.DataFrame(json_list)\n",
    "\n",
    "file_path = os.path.join(path_to_translation, \"prediction/{0}/{1}.json\".format(region, model))\n",
    "        \n",
    "with open(file_path, mode=\"rt\", encoding=\"utf-8\") as f:\n",
    "    json_list = json.loads(f.read())\n",
    "\n",
    "pred_df = pd.DataFrame(json_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e948fd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95000 95000\n"
     ]
    }
   ],
   "source": [
    "print(len(pred_df), len(reference_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13eb2191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chrf_of_prediction(path_to_translation, region, model, word_order=2):\n",
    "    file_path = os.path.join(path_to_translation, \"reference/{0}/reference.json\".format(region))\n",
    "    \n",
    "    json_list = []\n",
    "\n",
    "    with open(file_path, mode=\"rt\", encoding=\"utf-8\") as f:\n",
    "        json_list = json.loads(f.read())\n",
    "\n",
    "    reference_df = pd.DataFrame(json_list)\n",
    "    \n",
    "    file_path = os.path.join(path_to_translation, \"prediction/{0}/{1}.json\".format(region, model))\n",
    "        \n",
    "    with open(file_path, mode=\"rt\", encoding=\"utf-8\") as f:\n",
    "        json_list = json.loads(f.read())\n",
    "        \n",
    "    pred_df = pd.DataFrame(json_list)\n",
    "    \n",
    "    # 방언 부분집합 걸러내기\n",
    "    \n",
    "    # 두가지 점수 구하기\n",
    "    score_dict = dict()\n",
    "    \n",
    "    len_result = len(pred_df)\n",
    "    pred_score = compute_chrf_score(\n",
    "        y_pred=pred_df[\"prediction_target\"].to_list(),\n",
    "        y_true=reference_df.iloc[range(len_result)][\"standard_target\"].to_list(),\n",
    "        word_order=word_order\n",
    "    )\n",
    "    \n",
    "    score_dict={\"pred_chrf\": pred_score}\n",
    "    \n",
    "    return score_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064a2249",
   "metadata": {},
   "source": [
    "## 영어 pivot 성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1ae76e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chungcheong\n",
      "gangwon\n",
      "gyeongsang\n",
      "jeju\n",
      "jeonla\n",
      "{'chungcheong': {'pred_chrf': 30.041264515912943}, 'gangwon': {'pred_chrf': 28.35038718480748}, 'gyeongsang': {'pred_chrf': 30.06574848038776}, 'jeju': {'pred_chrf': 26.916914658319385}, 'jeonla': {'pred_chrf': 28.869409988253203}}\n"
     ]
    }
   ],
   "source": [
    "eval_dict = dict()\n",
    "\n",
    "regions = [\"chungcheong\", \"gangwon\", \"gyeongsang\", \"jeju\", \"jeonla\"]\n",
    "\n",
    "for r in regions:\n",
    "    print(r)\n",
    "    score_dict = chrf_of_prediction(\"./translation_en/\", r, \"opus-mt\")\n",
    "    eval_dict[r] = score_dict\n",
    "    \n",
    "print(eval_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ff49ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chungcheong\n",
      "gangwon\n",
      "gyeongsang\n",
      "jeju\n",
      "jeonla\n",
      "{'chungcheong': {'pred_chrf': 30.14948841492747}, 'gangwon': {'pred_chrf': 28.12401964733348}, 'gyeongsang': {'pred_chrf': 29.841671013957555}, 'jeju': {'pred_chrf': 26.690496367237614}, 'jeonla': {'pred_chrf': 29.0406218919269}}\n"
     ]
    }
   ],
   "source": [
    "for r in regions:\n",
    "    print(r)\n",
    "    score_dict = chrf_of_prediction(\"./translation_en/\", r, \"m2m_100_1.2B\")\n",
    "    eval_dict[r] = score_dict\n",
    "    \n",
    "print(eval_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c98ae21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chungcheong\n",
      "gangwon\n",
      "gyeongsang\n",
      "jeju\n",
      "jeonla\n",
      "{'chungcheong': {'pred_chrf': 41.9058010544727}, 'gangwon': {'pred_chrf': 39.61855267669251}, 'gyeongsang': {'pred_chrf': 42.09081791831114}, 'jeju': {'pred_chrf': 38.13848886796272}, 'jeonla': {'pred_chrf': 40.593375002203274}}\n"
     ]
    }
   ],
   "source": [
    "for r in regions:\n",
    "    print(r)\n",
    "    score_dict = chrf_of_prediction(\"./translation_en/\", r, \"exaone\")\n",
    "    eval_dict[r] = score_dict\n",
    "    \n",
    "print(eval_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41673f78",
   "metadata": {},
   "source": [
    "## 일본어 pivot 성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b697db92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chungcheong\n",
      "gangwon\n",
      "gyeongsang\n",
      "jeju\n",
      "jeonla\n",
      "{'chungcheong': {'pred_chrf': 14.380678718196432}, 'gangwon': {'pred_chrf': 12.68876939091021}, 'gyeongsang': {'pred_chrf': 14.424158191952651}, 'jeju': {'pred_chrf': 11.599434528493884}, 'jeonla': {'pred_chrf': 13.857333367274165}}\n"
     ]
    }
   ],
   "source": [
    "eval_dict = dict()\n",
    "\n",
    "regions = [\"chungcheong\", \"gangwon\", \"gyeongsang\", \"jeju\", \"jeonla\"]\n",
    "\n",
    "for r in regions:\n",
    "    print(r)\n",
    "    score_dict = chrf_of_prediction(\"./translation_jp/\", r, \"m2m_100_1.2B\", word_order=0)\n",
    "    eval_dict[r] = score_dict\n",
    "    \n",
    "print(eval_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc7907ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chungcheong\n",
      "gangwon\n",
      "gyeongsang\n",
      "jeju\n",
      "jeonla\n",
      "{'chungcheong': {'pred_chrf': 21.050896101710048}, 'gangwon': {'pred_chrf': 19.503125276915007}, 'gyeongsang': {'pred_chrf': 21.60154817262145}, 'jeju': {'pred_chrf': 17.85871736903309}, 'jeonla': {'pred_chrf': 20.39325998434969}}\n"
     ]
    }
   ],
   "source": [
    "eval_dict = dict()\n",
    "\n",
    "regions = [\"chungcheong\", \"gangwon\", \"gyeongsang\", \"jeju\", \"jeonla\"]\n",
    "\n",
    "for r in regions:\n",
    "    print(r)\n",
    "    score_dict = chrf_of_prediction(\"./translation_jp/\", r, \"exaone\", word_order=0)\n",
    "    eval_dict[r] = score_dict\n",
    "    \n",
    "print(eval_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9973e34b",
   "metadata": {},
   "source": [
    "## 중국어 pivot 성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d6aca7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chungcheong\n",
      "gangwon\n",
      "gyeongsang\n",
      "jeju\n",
      "jeonla\n",
      "{'chungcheong': {'pred_chrf': 10.334205253657267}, 'gangwon': {'pred_chrf': 9.648737011157108}, 'gyeongsang': {'pred_chrf': 10.62066027505951}, 'jeju': {'pred_chrf': 9.44489134653512}, 'jeonla': {'pred_chrf': 10.008641792506038}}\n"
     ]
    }
   ],
   "source": [
    "eval_dict = dict()\n",
    "\n",
    "regions = [\"chungcheong\", \"gangwon\", \"gyeongsang\", \"jeju\", \"jeonla\"]\n",
    "\n",
    "for r in regions:\n",
    "    print(r)\n",
    "    score_dict = chrf_of_prediction(\"./translation_zh/\", r, \"m2m_100_1.2B\", word_order=0)\n",
    "    eval_dict[r] = score_dict\n",
    "    \n",
    "print(eval_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7db20c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chungcheong\n",
      "gangwon\n",
      "gyeongsang\n",
      "jeju\n",
      "jeonla\n",
      "{'chungcheong': {'pred_chrf': 13.896448603001646}, 'gangwon': {'pred_chrf': 13.221778251097671}, 'gyeongsang': {'pred_chrf': 14.433445920854501}, 'jeju': {'pred_chrf': 12.735064472551002}, 'jeonla': {'pred_chrf': 13.423115083350293}}\n"
     ]
    }
   ],
   "source": [
    "eval_dict = dict()\n",
    "\n",
    "regions = [\"chungcheong\", \"gangwon\", \"gyeongsang\", \"jeju\", \"jeonla\"]\n",
    "\n",
    "for r in regions:\n",
    "    print(r)\n",
    "    score_dict = chrf_of_prediction(\"./translation_zh/\", r, \"exaone\", word_order=0)\n",
    "    eval_dict[r] = score_dict\n",
    "    \n",
    "print(eval_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2a0067",
   "metadata": {},
   "source": [
    "# 방언 부분집합에서의 chrf 성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b49e16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d35b62fc",
   "metadata": {},
   "source": [
    "# 방언 부분집합의 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d9da8465",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = \"gyeongsang\"\n",
    "m = \"opus-mt\"\n",
    "path_to_trans_result = \"./translation_en/baseline/\"\n",
    "path_to_reference = \"./translation_en/reference/\"\n",
    "\n",
    "trans_file_path = os.path.join(path_to_trans_result, \"{0}/{1}.json\".format(r, m))\n",
    "with open(trans_file_path, mode=\"rt\", encoding=\"utf-8\") as f:\n",
    "    json_list = json.loads(f.read())\n",
    "\n",
    "result_df = pd.DataFrame(json_list)\n",
    "dialect_df = result_df[result_df[\"dialect_source\"] != result_df[\"standard_source\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e616b597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89472 14174\n"
     ]
    }
   ],
   "source": [
    "print(len(result_df), len(dialect_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bb2c3a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = \"jeonla\"\n",
    "\n",
    "trans_file_path = os.path.join(path_to_trans_result, \"{0}/{1}.json\".format(r, m))\n",
    "with open(trans_file_path, mode=\"rt\", encoding=\"utf-8\") as f:\n",
    "    json_list = json.loads(f.read())\n",
    "\n",
    "result_df = pd.DataFrame(json_list)\n",
    "dialect_df = result_df[result_df[\"dialect_source\"] != result_df[\"standard_source\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9031ad1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110080 25727\n"
     ]
    }
   ],
   "source": [
    "print(len(result_df), len(dialect_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "548b6d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = \"jeju\"\n",
    "\n",
    "trans_file_path = os.path.join(path_to_trans_result, \"{0}/{1}.json\".format(r, m))\n",
    "with open(trans_file_path, mode=\"rt\", encoding=\"utf-8\") as f:\n",
    "    json_list = json.loads(f.read())\n",
    "\n",
    "result_df = pd.DataFrame(json_list)\n",
    "dialect_df = result_df[result_df[\"dialect_source\"] != result_df[\"standard_source\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aabdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79872 42669\n"
     ]
    }
   ],
   "source": [
    "print(len(result_df), len(dialect_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4cdf01d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = \"gangwon\"\n",
    "\n",
    "trans_file_path = os.path.join(path_to_trans_result, \"{0}/{1}.json\".format(r, m))\n",
    "with open(trans_file_path, mode=\"rt\", encoding=\"utf-8\") as f:\n",
    "    json_list = json.loads(f.read())\n",
    "\n",
    "result_df = pd.DataFrame(json_list)\n",
    "dialect_df = result_df[result_df[\"dialect_source\"] != result_df[\"standard_source\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fc90b5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91008 24084\n"
     ]
    }
   ],
   "source": [
    "print(len(result_df), len(dialect_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6be45e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = \"chungcheong\"\n",
    "\n",
    "trans_file_path = os.path.join(path_to_trans_result, \"{0}/{1}.json\".format(r, m))\n",
    "with open(trans_file_path, mode=\"rt\", encoding=\"utf-8\") as f:\n",
    "    json_list = json.loads(f.read())\n",
    "\n",
    "result_df = pd.DataFrame(json_list)\n",
    "dialect_df = result_df[result_df[\"dialect_source\"] != result_df[\"standard_source\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "84183a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94848 15601\n"
     ]
    }
   ],
   "source": [
    "print(len(result_df), len(dialect_df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
